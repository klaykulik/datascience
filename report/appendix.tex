\section{}
\label{sec:appa}
\begin{lstlisting}[language=Python, caption=CNN for galaxy classification with TensorFlow]
model = Sequential()
model.add(Conv2D(32, (3,3), input_shape=(img_data.shape[1], img_data.shape[2], img_data.shape[3]), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64, (3,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(128, (3,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, (3,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64, (3,3), activation="relu"))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(128, activation="relu"))
model.add(Dropout(0.3))

model.add(Dense(1, activation="sigmoid"))
model.compile(loss="binary_crossentropy", optimizer=keras.optimizers.Adam(lr=0.0001), metrics=["accuracy"])

metrics = model.fit(img_data, labels, batch_size=32, validation_split=0.3, epochs=30)

plt.plot(metrics.history["acc"])
plt.plot(metrics.history["loss"])
plt.plot(metrics.history["val_acc"])
plt.plot(metrics.history["val_loss"])
plt.legend(["acc", "loss", "val_acc", "val_loss"], loc=3)
plt.show()

model.summary()
\end{lstlisting}


\begin{lstlisting}[language=Python, caption=Full result of the CNN model]
Train on 26681 samples, validate on 11436 samples
Epoch 1/30
26681/26681 [==============================] - 761s 29ms/step - loss: 0.4788 - acc: 0.7636 - val_loss: 0.4086 - val_acc: 0.8261
Epoch 2/30
26681/26681 [==============================] - 614s 23ms/step - loss: 0.3087 - acc: 0.8720 - val_loss: 0.2370 - val_acc: 0.9053
Epoch 3/30
26681/26681 [==============================] - 603s 23ms/step - loss: 0.2433 - acc: 0.9058 - val_loss: 0.2137 - val_acc: 0.9227
Epoch 4/30
26681/26681 [==============================] - 600s 23ms/step - loss: 0.2038 - acc: 0.9236 - val_loss: 0.1723 - val_acc: 0.9359
Epoch 5/30
26681/26681 [==============================] - 602s 23ms/step - loss: 0.1675 - acc: 0.9368 - val_loss: 0.1495 - val_acc: 0.9479
Epoch 6/30
26681/26681 [==============================] - 615s 23ms/step - loss: 0.1471 - acc: 0.9454 - val_loss: 0.1685 - val_acc: 0.9375
Epoch 7/30
26681/26681 [==============================] - 612s 23ms/step - loss: 0.1295 - acc: 0.9544 - val_loss: 0.1071 - val_acc: 0.9634
Epoch 8/30
26681/26681 [==============================] - 617s 23ms/step - loss: 0.1213 - acc: 0.9551 - val_loss: 0.1053 - val_acc: 0.9621
Epoch 9/30
26681/26681 [==============================] - 614s 23ms/step - loss: 0.1095 - acc: 0.9610 - val_loss: 0.0980 - val_acc: 0.9663
Epoch 10/30
26681/26681 [==============================] - 607s 23ms/step - loss: 0.1035 - acc: 0.9634 - val_loss: 0.1086 - val_acc: 0.9601
Epoch 11/30
26681/26681 [==============================] - 619s 23ms/step - loss: 0.0986 - acc: 0.9646 - val_loss: 0.0866 - val_acc: 0.9676
Epoch 12/30
26681/26681 [==============================] - 646s 24ms/step - loss: 0.0971 - acc: 0.9650 - val_loss: 0.0961 - val_acc: 0.9640
Epoch 13/30
26681/26681 [==============================] - 632s 24ms/step - loss: 0.0939 - acc: 0.9654 - val_loss: 0.0803 - val_acc: 0.9742
Epoch 14/30
26681/26681 [==============================] - 618s 23ms/step - loss: 0.0893 - acc: 0.9680 - val_loss: 0.0766 - val_acc: 0.9735
Epoch 15/30
26681/26681 [==============================] - 617s 23ms/step - loss: 0.0841 - acc: 0.9696 - val_loss: 0.0737 - val_acc: 0.9747
Epoch 16/30
26681/26681 [==============================] - 617s 23ms/step - loss: 0.0817 - acc: 0.9698 - val_loss: 0.0886 - val_acc: 0.9671
Epoch 17/30
26681/26681 [==============================] - 612s 23ms/step - loss: 0.0800 - acc: 0.9702 - val_loss: 0.0728 - val_acc: 0.9739
Epoch 18/30
26681/26681 [==============================] - 621s 23ms/step - loss: 0.0755 - acc: 0.9729 - val_loss: 0.0681 - val_acc: 0.9764
Epoch 19/30
26681/26681 [==============================] - 623s 23ms/step - loss: 0.0720 - acc: 0.9741 - val_loss: 0.0647 - val_acc: 0.9777
Epoch 20/30
26681/26681 [==============================] - 626s 23ms/step - loss: 0.0703 - acc: 0.9759 - val_loss: 0.0798 - val_acc: 0.9711
Epoch 21/30
26681/26681 [==============================] - 621s 23ms/step - loss: 0.0633 - acc: 0.9780 - val_loss: 0.0646 - val_acc: 0.9760
Epoch 22/30
26681/26681 [==============================] - 616s 23ms/step - loss: 0.0628 - acc: 0.9774 - val_loss: 0.0558 - val_acc: 0.9815
Epoch 23/30
26681/26681 [==============================] - 619s 23ms/step - loss: 0.0601 - acc: 0.9789 - val_loss: 0.0746 - val_acc: 0.9750
Epoch 24/30
26681/26681 [==============================] - 623s 23ms/step - loss: 0.0630 - acc: 0.9778 - val_loss: 0.0738 - val_acc: 0.9762
Epoch 25/30
26681/26681 [==============================] - 625s 23ms/step - loss: 0.0572 - acc: 0.9799 - val_loss: 0.0511 - val_acc: 0.9835
Epoch 26/30
26681/26681 [==============================] - 625s 23ms/step - loss: 0.0517 - acc: 0.9828 - val_loss: 0.0480 - val_acc: 0.9835
Epoch 27/30
26681/26681 [==============================] - 619s 23ms/step - loss: 0.0500 - acc: 0.9824 - val_loss: 0.0583 - val_acc: 0.9789
Epoch 28/30
26681/26681 [==============================] - 619s 23ms/step - loss: 0.0497 - acc: 0.9824 - val_loss: 0.0607 - val_acc: 0.9785
Epoch 29/30
26681/26681 [==============================] - 622s 23ms/step - loss: 0.0490 - acc: 0.9831 - val_loss: 0.0423 - val_acc: 0.9853
Epoch 30/30
26681/26681 [==============================] - 621s 23ms/step - loss: 0.0460 - acc: 0.9838 - val_loss: 0.0452 - val_acc: 0.9850

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 198, 198, 32)      1472      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 99, 99, 32)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 97, 97, 64)        18496     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 48, 48, 64)        0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 46, 46, 128)       73856     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 23, 23, 128)       0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 23, 23, 128)       0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 21, 21, 128)       147584    
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 10, 10, 128)       0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 8, 8, 64)          73792     
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 4, 4, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 128)               131200    
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 129       
=================================================================
Total params: 446,529
Trainable params: 446,529
Non-trainable params: 0
\end{lstlisting}