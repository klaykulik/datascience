\section{Discussion}
\label{sec:dis}
The CNN model was trained and validated on the Galaxy Zoo data that had crowdsourced classifications, so it is possible that any bias and errors in the input data were also learned by the model. 
That being said, we could also propose that errors in the crowdsourced data are shown as misclassifications in our model, and our model is perfectly classifying the data, however unlikely that may seem. 
The only way to definitively find out the true accuracy that our model has when classifying galaxy morphology would be to manually classify all of the galaxies and compare the results. 
It would be interesting to compare the same model with image data (RGB) extracted for the same galaxies instead of `ugriz' channels. This would tell us how useful the extra information from the `ugriz' channels is for the classification of the galaxies.
With more training data and visualization of the weights at every layer we should be able to get a clear idea on what the model learned.

From the results it is clear that we can employ a CNN model in practice, even though this model was only trained on a subset of the data available in GZ.
One particular example of an application of our CNN would be with the SDSS database itself. Sloan does not classify the galaxy images it produces due to the sheer volume of data, but a CNN could easily allow for classification as soon as galaxies are observed. 


